import cv2
import numpy as np
import time


class HighAccuracyVisualOdometry:
    """–í–∏–∑—É–∞–ª—å–Ω—ã–π –æ–¥–æ–º–µ—Ç—Ä —Å –ø–æ–≤—ã—à–µ–Ω–Ω–æ–π —Ç–æ—á–Ω–æ—Å—Ç—å—é"""

    def __init__(self, use_deep_learning=True, scale_factor=1.0):
        self.use_deep_learning = use_deep_learning
        self.scale_factor = scale_factor

        # –£–í–ï–õ–ò–ß–ï–ù–ù–û–ï –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ features –¥–ª—è –±–æ–ª—å—à–µ–π —Ç–æ—á–Ω–æ—Å—Ç–∏
        self.orb = cv2.ORB_create(nfeatures=2000, scaleFactor=1.1, nlevels=8, edgeThreshold=15)

        # –ë–æ–ª–µ–µ —Å—Ç—Ä–æ–≥–∏–π –º–∞—Ç—á–∏–Ω–≥
        FLANN_INDEX_LSH = 6
        index_params = dict(algorithm=FLANN_INDEX_LSH,
                            table_number=12,  # –£–≤–µ–ª–∏—á–∏–ª
                            key_size=20,  # –£–≤–µ–ª–∏—á–∏–ª
                            multi_probe_level=2)  # –£–≤–µ–ª–∏—á–∏–ª
        search_params = dict(checks=100)  # –ë–æ–ª—å—à–µ –ø—Ä–æ–≤–µ—Ä–æ–∫
        self.flann = cv2.FlannBasedMatcher(index_params, search_params)

        # –ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ –∫–∞–º–µ—Ä—ã (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è)
        self.camera_matrix = np.array([[800, 0, 320],
                                       [0, 800, 180],
                                       [0, 0, 1]], dtype=np.float32)
        self.dist_coeffs = np.zeros(4)

        # –£–ª—É—á—à–µ–Ω–Ω–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
        self.trajectory = [[0.0, 0.0, 0.0]]
        self.prev_frame = None
        self.prev_kp = None
        self.prev_des = None
        self.frame_count = 0
        self.turn_points = []
        self.processing_times = []

        # –î–ª—è —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–∏
        self.pose_buffer = []
        self.buffer_size = 5

    def process_frame(self, frame):
        start_time = time.time()
        self.frame_count += 1

        # –£–õ–£–ß–®–ï–ù–ù–ê–Ø –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞
        processed_frame = self._enhanced_preprocess(frame)
        gray = cv2.cvtColor(processed_frame, cv2.COLOR_BGR2GRAY)

        # –î–µ—Ç–µ–∫—Ü–∏—è —Å –ª—É—á—à–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
        kp, des = self.orb.detectAndCompute(gray, None)

        if self.prev_frame is not None and des is not None and self.prev_des is not None:
            try:
                # –°–¢–†–û–ì–ò–ô –º–∞—Ç—á–∏–Ω–≥
                matches = self.flann.knnMatch(self.prev_des, des, k=2)

                # –ñ–µ—Å—Ç–∫–∏–π —Ñ–∏–ª—å—Ç—Ä Lowe's ratio test
                good_matches = []
                for match_pair in matches:
                    if len(match_pair) == 2:
                        m, n = match_pair
                        if m.distance < 0.6 * n.distance:  # –ë–æ–ª–µ–µ —Å—Ç—Ä–æ–≥–∏–π –ø–æ—Ä–æ–≥
                            good_matches.append(m)

                # –ú–ò–ù–ò–ú–£–ú —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π —É–≤–µ–ª–∏—á–µ–Ω
                if len(good_matches) > 30:  # –ë—ã–ª–æ 20
                    src_pts = np.float32([self.prev_kp[m.queryIdx].pt for m in good_matches])
                    dst_pts = np.float32([kp[m.trainIdx].pt for m in good_matches])

                    # –£–õ–£–ß–®–ï–ù–ù–´–ô RANSAC
                    M, mask = cv2.estimateAffinePartial2D(
                        src_pts, dst_pts,
                        method=cv2.RANSAC,
                        ransacReprojThreshold=2.0,  # –ë–æ–ª–µ–µ —Å—Ç—Ä–æ–≥–∏–π
                        confidence=0.995,  # –í—ã—à–µ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
                        maxIters=2000  # –ë–æ–ª—å—à–µ –∏—Ç–µ—Ä–∞—Ü–∏–π
                    )

                    if M is not None:
                        inlier_count = np.sum(mask)
                        inlier_ratio = inlier_count / len(good_matches)

                        # –¢–æ–ª—å–∫–æ –ø—Ä–∏ —Ö–æ—Ä–æ—à–µ–º –∫–∞—á–µ—Å—Ç–≤–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π
                        if inlier_ratio > 0.6 and inlier_count > 20:  # –°—Ç—Ä–æ–∂–µ
                            # –£–õ–£–ß–®–ï–ù–ù–û–ï –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ
                            dx = M[0, 2] * 0.003 * self.scale_factor  # –ë–æ–ª–µ–µ —Ç–æ—á–Ω—ã–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç
                            dy = M[1, 2] * 0.003 * self.scale_factor

                            rotation = np.arctan2(M[1, 0], M[0, 0])

                            # –°–ì–õ–ê–ñ–ò–í–ê–ù–ò–ï —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–∏
                            new_pos = self._smooth_trajectory([
                                self.trajectory[-1][0] + dx,
                                self.trajectory[-1][1] + dy,
                                self.trajectory[-1][2] + rotation * 0.05  # –ú–µ–Ω—å—à–µ –≤–ª–∏—è–Ω–∏–µ –≤—Ä–∞—â–µ–Ω–∏—è
                            ])

                            self.trajectory.append(new_pos)
                            self._detect_turns_improved()

            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–∞–¥—Ä–∞ {self.frame_count}: {e}")
                # –ö–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ã–π –ø–æ–¥—Ö–æ–¥ - –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –¥–≤–∏–∂–µ–Ω–∏–µ
                self.trajectory.append(self.trajectory[-1].copy())

        self.prev_frame = gray
        self.prev_kp = kp
        self.prev_des = des

        processing_time = time.time() - start_time
        self.processing_times.append(processing_time)

        return self.trajectory[-1]

    def _enhanced_preprocess(self, frame):
        """–£–ª—É—á—à–µ–Ω–Ω–∞—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–¥—Ä–∞"""
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ –¥–ª—è —Ç–æ—á–Ω–æ—Å—Ç–∏
        if frame.shape[1] > 960:  # –ú–µ–Ω—å—à–µ —Ä–µ—Å–∞–π–∑ –¥–ª—è —Ç–æ—á–Ω–æ—Å—Ç–∏
            frame = cv2.resize(frame, (960, 540))

        # –£–ª—É—á—à–µ–Ω–Ω–æ–µ –ø–æ–≤—ã—à–µ–Ω–∏–µ –∫–æ–Ω—Ç—Ä–∞—Å—Ç–∞
        lab = cv2.cvtColor(frame, cv2.COLOR_BGR2LAB)
        lab[:, :, 0] = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8)).apply(lab[:, :, 0])
        frame = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)

        # –õ–µ–≥–∫–æ–µ —à—É–º–æ–ø–æ–¥–∞–≤–ª–µ–Ω–∏–µ
        frame = cv2.medianBlur(frame, 3)

        return frame

    def _smooth_trajectory(self, new_pos):
        """–°–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–∏ —Å–∫–æ–ª—å–∑—è—â–∏–º —Å—Ä–µ–¥–Ω–∏–º"""
        self.pose_buffer.append(new_pos)
        if len(self.pose_buffer) > self.buffer_size:
            self.pose_buffer.pop(0)

        # –°—Ä–µ–¥–Ω–µ–µ –ø–æ –±—É—Ñ–µ—Ä—É
        smoothed = np.mean(self.pose_buffer, axis=0)
        return smoothed.tolist()

    def _detect_turns_improved(self, window_size=20):  # –£–≤–µ–ª–∏—á–∏–ª –æ–∫–Ω–æ
        """–£–ª—É—á—à–µ–Ω–Ω–∞—è –¥–µ—Ç–µ–∫—Ü–∏—è –ø–æ–≤–æ—Ä–æ—Ç–æ–≤"""
        if len(self.trajectory) < window_size + 1:
            return

        i = len(self.trajectory) - 1

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª—å—à–µ –∫–∞–¥—Ä–æ–≤ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
        start_idx = max(0, i - window_size)
        mid_idx = start_idx + window_size // 2

        # –í–µ–∫—Ç–æ—Ä—ã –¥–æ –∏ –ø–æ—Å–ª–µ
        vec_before = [
            self.trajectory[mid_idx][0] - self.trajectory[start_idx][0],
            self.trajectory[mid_idx][1] - self.trajectory[start_idx][1]
        ]

        vec_after = [
            self.trajectory[i][0] - self.trajectory[mid_idx][0],
            self.trajectory[i][1] - self.trajectory[mid_idx][1]
        ]

        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤–µ–∫—Ç–æ—Ä—ã
        norm_before = np.linalg.norm(vec_before)
        norm_after = np.linalg.norm(vec_after)

        if norm_before > 0.1 and norm_after > 0.1:  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –¥–≤–∏–∂–µ–Ω–∏–µ
            vec_before = [v / norm_before for v in vec_before]
            vec_after = [v / norm_after for v in vec_after]

            # –£–≥–æ–ª —á–µ—Ä–µ–∑ —Å–∫–∞–ª—è—Ä–Ω–æ–µ –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ
            dot_product = vec_before[0] * vec_after[0] + vec_before[1] * vec_after[1]
            dot_product = np.clip(dot_product, -1.0, 1.0)
            angle_rad = np.arccos(dot_product)
            angle_deg = np.degrees(angle_rad)

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —á–µ—Ä–µ–∑ –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ
            cross_product = vec_before[0] * vec_after[1] - vec_before[1] * vec_after[0]
            turn_type = 'left' if cross_product > 0 else 'right'

            # –ë–æ–ª–µ–µ —Å—Ç—Ä–æ–≥–∏–π –ø–æ—Ä–æ–≥ –¥–ª—è –ø–æ–≤–æ—Ä–æ—Ç–æ–≤
            if angle_deg > 20:  # –ë—ã–ª–æ 15
                turn_info = {
                    'frame_index': self.frame_count,
                    'trajectory_index': i,
                    'angle_degrees': round(angle_deg, 1),
                    'position': self.trajectory[i].copy(),
                    'turn_type': turn_type
                }

                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –¥—É–±–ª–∏–∫–∞—Ç—ã
                if not self.turn_points or abs(i - self.turn_points[-1]['trajectory_index']) > 15:
                    self.turn_points.append(turn_info)
                    print(f"üîÑ –û–±–Ω–∞—Ä—É–∂–µ–Ω –ø–æ–≤–æ—Ä–æ—Ç: {turn_info['turn_type']} {angle_deg:.1f}¬∞")

    # –û—Å—Ç–∞–ª—å–Ω—ã–µ –º–µ—Ç–æ–¥—ã –æ—Å—Ç–∞—é—Ç—Å—è
    def set_scale_factor(self, scale_factor):
        self.scale_factor = scale_factor
        print(f"üìè –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –º–∞—Å—à—Ç–∞–±: {scale_factor}")

    def get_trajectory(self):
        return self.trajectory

    def get_turn_points(self):
        return self.turn_points

    def get_statistics(self):
        if not self.processing_times:
            return {}

        total_distance = self._calculate_distance(self.trajectory)

        return {
            'total_frames': self.frame_count,
            'trajectory_points': len(self.trajectory),
            'estimated_distance': total_distance,
            'avg_processing_time': np.mean(self.processing_times),
            'total_processing_time': np.sum(self.processing_times),
            'fps': 1.0 / np.mean(self.processing_times) if np.mean(self.processing_times) > 0 else 0,
            'scale_factor': self.scale_factor,
            'turns_detected': len(self.turn_points)
        }

    def _calculate_distance(self, trajectory):
        if len(trajectory) < 2:
            return 0.0
        distance = 0.0
        for i in range(1, len(trajectory)):
            dx = trajectory[i][0] - trajectory[i - 1][0]
            dy = trajectory[i][1] - trajectory[i - 1][1]
            dz = trajectory[i][2] - trajectory[i - 1][2]
            segment_distance = (dx ** 2 + dy ** 2 + dz ** 2) ** 0.5
            distance += segment_distance
        return distance

    def reset(self):
        self.__init__(use_deep_learning=self.use_deep_learning, scale_factor=self.scale_factor)